{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "6q7dDydT7n2d",
    "outputId": "be47d969-c754-4cdd-f6d5-db210bcb30b6"
   },
   "outputs": [],
   "source": [
    "!wget http://www.manythings.org/anki/cmn-eng.zip\n",
    "!unzip -d ./cmn-eng cmn-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zo7QCacp7n2s"
   },
   "outputs": [],
   "source": [
    "seed = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05LtExs57n20"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext import data\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from torchtext.vocab import Vectors\n",
    "import time\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from torchtext.vocab import GloVe\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B7h691pQdmyW"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QW9iTQeF7n2-"
   },
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = word_tokenize\n",
    "Article = data.Field(sequential=True, tokenize=tokenize, lower=True, init_token='<bos>', eos_token='<eos>',\n",
    "                  pad_token='<pad>', unk_token='<oov>')\n",
    "Title = data.Field(sequential=True, tokenize=tokenize, lower=True, eos_token='<eos>', \n",
    "                  pad_token='<pad>', unk_token='<oov>')\n",
    "Len = data.Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'train_data.csv'\n",
    "valid_path = 'valid_data.csv'\n",
    "test_path = 'test_data.csv'\n",
    "\n",
    "\n",
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, csv_path, article_field, title_field, test=False, **kwargs):\n",
    "\n",
    "        csv_data = pd.read_csv(csv_path)\n",
    "        fields = [(\"id\", None), (\"article\", article_field), (\"title\", title_field), (\"art_len\", Len), (\"title_len\", Len)]\n",
    "        examples = []\n",
    "        if test:\n",
    "            for text in tqdm(csv_data['article']):\n",
    "                examples.append(data.Example.fromlist([None, text, None], fields))\n",
    "        else:\n",
    "            for text, label in tqdm(zip(csv_data['article'], csv_data['title'])):\n",
    "                examples.append(data.Example.fromlist([None, text, label, len(word_tokenize(text))+2, len(word_tokenize(label))+1], fields))\n",
    "        super(MyDataset, self).__init__(examples, fields)\n",
    "\n",
    "    def shuffle(self, text):\n",
    "        text = np.random.permutation(text.strip().split())\n",
    "        return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MyDataset(train_path, article_field=Article, title_field=Title, test=False)\n",
    "valid = MyDataset(valid_path, article_field=Article, title_field=Title, test=False)\n",
    "test = MyDataset(test_path, article_field=Article, title_field=Title, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "vectors = Vectors(name='glove-wiki-gigaword-300.txt')\n",
    "Article.build_vocab(train, valid, test, vectors=vectors)\n",
    "default = Article.vocab.stoi['<oov>']\n",
    "Article.vocab.stoi.default_factory = lambda: default\n",
    "Title.vocab = Article.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title.vocab = Article.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator\n",
    "\n",
    "train_iter, val_iter = BucketIterator.splits(\n",
    "        (train, valid), \n",
    "        batch_size=16, \n",
    "        device=device, \n",
    "        sort_key=lambda x: len(x.article),\n",
    "        sort_within_batch=True,\n",
    "        repeat=False \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "\n",
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F19j3Svn7n3v"
   },
   "source": [
    "## Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qsKXeDY7n3w"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout=0.5, bidirectional=True):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        weight_matrix = Article.vocab.vectors\n",
    "        self.embedding.weight.data.copy_(weight_matrix)\n",
    "        self.gru = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout, bidirectional=bidirectional)\n",
    "        \n",
    "    def forward(self, input_seqs, input_lengths, hidden):\n",
    "        # input_seqs = [seq_len, batch]\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        # embedded = [seq_len, batch, embed_dim]\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths, enforce_sorted=False)\n",
    "        \n",
    "        outputs, hidden = self.gru(packed, hidden)        \n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "#         print('hidden',hidden.shape())\n",
    "        # outputs = [seq_len, batch, hid_dim * n directions]\n",
    "        # output_lengths = [batch]\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WdZchKu7n33"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout=0.5, bidirectional=True):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        weight_matrix = Article.vocab.vectors\n",
    "        self.embedding.weight.data.copy_(weight_matrix)\n",
    "        self.gru = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout, bidirectional=bidirectional)\n",
    "        \n",
    "        if bidirectional:\n",
    "            self.fc_out = nn.Linear(hid_dim*2, output_dim)\n",
    "        else:\n",
    "            self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, token_inputs, hidden):\n",
    "        # token_inputs = [batch]\n",
    "        batch_size = token_inputs.size(0)\n",
    "        embedded = self.dropout(self.embedding(token_inputs).view(1, batch_size, -1))\n",
    "        # embedded = [1, batch, emb_dim]\n",
    "\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        \n",
    "        output = self.fc_out(output.squeeze(0))\n",
    "        output = self.softmax(output)\n",
    "        # output = [batch, output_dim]\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tkDLZQVR7n4A"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, \n",
    "                 encoder, \n",
    "                 decoder, \n",
    "                 device, \n",
    "                 predict=False, \n",
    "                 basic_dict=None,\n",
    "                 max_len=100\n",
    "                 ):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        self.predict = predict  \n",
    "        self.basic_dict = basic_dict  \n",
    "        self.max_len = max_len  \n",
    "\n",
    "        self.enc_n_layers = self.encoder.gru.num_layers\n",
    "        self.enc_n_directions = 2 if self.encoder.gru.bidirectional else 1\n",
    "        self.dec_n_directions = 2 if self.decoder.gru.bidirectional else 1\n",
    "\n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        assert self.enc_n_directions >= self.dec_n_directions, \\\n",
    "            \"If decoder is bidirectional, encoder must be bidirectional either!\"\n",
    "        \n",
    "    def forward(self, input_batches, input_lengths, target_batches=None, target_lengths=None, teacher_forcing_ratio=0.5):\n",
    "        # input_batches = target_batches = [seq_len, batch]\n",
    "        batch_size = input_batches.size(1)\n",
    "        BOS_token = self.basic_dict[\"<bos>\"]\n",
    "        EOS_token = self.basic_dict[\"<eos>\"]\n",
    "        PAD_token = self.basic_dict[\"<pad>\"]\n",
    "\n",
    "        encoder_hidden = torch.zeros(self.enc_n_layers*self.enc_n_directions, batch_size, self.encoder.hid_dim, device=self.device)\n",
    "        \n",
    "        # encoder_output = [seq_len, batch, hid_dim * n directions]\n",
    "        # encoder_hidden = [n_layers*n_directions, batch, hid_dim]\n",
    "        encoder_output, encoder_hidden = self.encoder(\n",
    "            input_batches, input_lengths, encoder_hidden)\n",
    "\n",
    "      \n",
    "        decoder_input = torch.tensor([BOS_token] * batch_size, dtype=torch.long, device=self.device)\n",
    "        if self.enc_n_directions == self.dec_n_directions:\n",
    "            decoder_hidden = encoder_hidden\n",
    "        else:\n",
    "            L = encoder_hidden.size(0)\n",
    "            decoder_hidden = encoder_hidden[range(0, L, 2)] + encoder_hidden[range(1, L, 2)]\n",
    "\n",
    "        if self.predict:\n",
    "            assert batch_size == 1, \"batch_size of predict phase must be 1!\"\n",
    "            output_tokens = []\n",
    "\n",
    "            while True:\n",
    "                decoder_output, decoder_hidden = self.decoder(\n",
    "                    decoder_input, decoder_hidden\n",
    "                )\n",
    "               \n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(1)  \n",
    "                output_token = topi.squeeze().detach().item()\n",
    "                if output_token == EOS_token or len(output_tokens) == self.max_len:\n",
    "                    break\n",
    "                output_tokens.append(output_token)\n",
    "            return output_tokens\n",
    "\n",
    "        else:\n",
    "            max_target_length = max(target_lengths)\n",
    "            all_decoder_outputs = torch.zeros((max_target_length, batch_size, self.decoder.output_dim), device=self.device)\n",
    "\n",
    "            for t in range(max_target_length):\n",
    "                use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "                if use_teacher_forcing:\n",
    "                    # decoder_output = [batch, output_dim]\n",
    "                    # decoder_hidden = [n_layers*n_directions, batch, hid_dim]\n",
    "                    decoder_output, decoder_hidden = self.decoder(\n",
    "                        decoder_input, decoder_hidden\n",
    "                    )\n",
    "                    all_decoder_outputs[t] = decoder_output\n",
    "                    decoder_input = target_batches[t]  \n",
    "                else:\n",
    "                    decoder_output, decoder_hidden = self.decoder(\n",
    "                        decoder_input, decoder_hidden\n",
    "                    )\n",
    "                    # [batch, 1]\n",
    "                    topv, topi = decoder_output.topk(1)\n",
    "                    all_decoder_outputs[t] = decoder_output\n",
    "                    decoder_input = topi.squeeze(1)  \n",
    "     \n",
    "            loss_fn = nn.NLLLoss(ignore_index=PAD_token)\n",
    "            loss = loss_fn(\n",
    "                all_decoder_outputs.reshape(-1,self.decoder.output_dim ),  # [batch*seq_len, output_dim]\n",
    "                target_batches.reshape(-1)                                                 # [batch*seq_len]\n",
    "            )\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TvUaEp0Y7n4H"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FcB6O0cJ7n4P"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    data_loader, \n",
    "    optimizer, \n",
    "    clip=1, \n",
    "    teacher_forcing_ratio=0.5, \n",
    "    print_every=1  \n",
    "    ):\n",
    "    model.predict = False\n",
    "    model.train()\n",
    "\n",
    "    if print_every == 0:\n",
    "        print_every = 1\n",
    "\n",
    "    print_loss_total = 0  \n",
    "    start = time.time()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch in tqdm(data_loader, position=0, leave=True):\n",
    "        step += 1\n",
    "        input_batchs = batch.article\n",
    "        target_batchs = batch.title\n",
    "        input_lens = list(batch.art_len)\n",
    "        target_lens = list(batch.title_len)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(input_batchs, input_lens, target_batchs, target_lens, teacher_forcing_ratio)\n",
    "        print_loss_total += loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 500 == 0:\n",
    "            print_loss_avg = print_loss_total / 500\n",
    "            print_loss_total = 0\n",
    "            print('\\tCurrent Loss: %.4f' % print_loss_avg)\n",
    "\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DgYv7rsp7n4V"
   },
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    model,\n",
    "    data_loader, \n",
    "    print_every=None\n",
    "    ):\n",
    "    model.predict = False\n",
    "    model.eval()\n",
    "    if print_every == 0:\n",
    "        print_every = 1\n",
    "\n",
    "    print_loss_total = 0  \n",
    "    start = time.time()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader): \n",
    "            input_batchs = batch.article\n",
    "            target_batchs = batch.title\n",
    "            input_lens = list(batch.art_len)\n",
    "            target_lens = list(batch.title_len)\n",
    "        \n",
    "            loss = model(input_batchs, input_lens, target_batchs, target_lens, teacher_forcing_ratio=0)\n",
    "            print_loss_total += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            if print_every and (i+1) % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('\\tCurrent Loss: %.4f' % print_loss_avg)\n",
    "\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ldcZM35r7n4h"
   },
   "outputs": [],
   "source": [
    "def summary(\n",
    "    model,\n",
    "    sample, \n",
    "    idx2token=None\n",
    "    ):\n",
    "    model.predict = True\n",
    "    model.eval()\n",
    "\n",
    "    # shape = [seq_len, 1]\n",
    "    input_batch = sample['src']\n",
    "    input_len = sample['src_len']\n",
    "\n",
    "    output_tokens = model(input_batch, input_len)\n",
    "    output_tokens = [idx2token[t] for t in output_tokens]\n",
    "\n",
    "    return \" \".join(output_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9luHxDc7n4q"
   },
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QSLPWwzT7n4s",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(Article.vocab.stoi)\n",
    "OUTPUT_DIM = len(Article.vocab.stoi)\n",
    "ENC_EMB_DIM = 300\n",
    "DEC_EMB_DIM = 300\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "LEARNING_RATE = 1e-4\n",
    "N_EPOCHS = 200\n",
    "CLIP = 1\n",
    "\n",
    "bidirectional = True\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT, bidirectional)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT, bidirectional)\n",
    "model = Seq2Seq(enc, dec, device, basic_dict=Article.vocab.stoi).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f7AKhdoGdm2g"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "model.load_state_dict(torch.load('seq2seq.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = Article.vocab.stoi\n",
    "sample = test[116].article\n",
    "print(sample)\n",
    "print(test[116].title)\n",
    "sample = [dct['<bos>']] + [dct[ele] for ele in sample] + [dct['<eos>']]\n",
    "\n",
    "test_sample = {}\n",
    "test_sample[\"src\"] = torch.tensor(sample, dtype=torch.long, device=device).reshape(-1, 1)\n",
    "test_sample[\"src_len\"] = [len(sample)]\n",
    "\n",
    "print(summary(model, test_sample, Article.vocab.itos), end=\"\\n\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iter1, iter2 = BucketIterator.splits(\n",
    "        (train, valid), \n",
    "        batch_size=4, \n",
    "        device=device, # 如果使用gpu，将-1更换为GPU的编号\n",
    "        sort_key=lambda x: len(x.article),\n",
    "        sort_within_batch=True,\n",
    "        repeat=False \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Seq2Seq.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
